{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>991</th>\n",
       "      <th>992</th>\n",
       "      <th>993</th>\n",
       "      <th>994</th>\n",
       "      <th>995</th>\n",
       "      <th>996</th>\n",
       "      <th>997</th>\n",
       "      <th>998</th>\n",
       "      <th>999</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.086678</td>\n",
       "      <td>0.007570</td>\n",
       "      <td>-0.001760</td>\n",
       "      <td>-0.119879</td>\n",
       "      <td>0.025078</td>\n",
       "      <td>-0.057182</td>\n",
       "      <td>0.029155</td>\n",
       "      <td>0.016894</td>\n",
       "      <td>0.082843</td>\n",
       "      <td>-0.084654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.187143</td>\n",
       "      <td>-0.049634</td>\n",
       "      <td>-0.135729</td>\n",
       "      <td>-0.168967</td>\n",
       "      <td>-0.101840</td>\n",
       "      <td>-0.059187</td>\n",
       "      <td>-0.523092</td>\n",
       "      <td>-0.014308</td>\n",
       "      <td>0.222151</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.028979</td>\n",
       "      <td>0.035377</td>\n",
       "      <td>0.017578</td>\n",
       "      <td>-0.083165</td>\n",
       "      <td>0.102731</td>\n",
       "      <td>-0.049929</td>\n",
       "      <td>-0.021335</td>\n",
       "      <td>0.058517</td>\n",
       "      <td>0.053307</td>\n",
       "      <td>-0.085223</td>\n",
       "      <td>...</td>\n",
       "      <td>0.356400</td>\n",
       "      <td>0.355215</td>\n",
       "      <td>-0.028688</td>\n",
       "      <td>-0.065168</td>\n",
       "      <td>-0.171425</td>\n",
       "      <td>0.204379</td>\n",
       "      <td>0.191221</td>\n",
       "      <td>0.038517</td>\n",
       "      <td>-0.241319</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.029658</td>\n",
       "      <td>0.035590</td>\n",
       "      <td>0.020067</td>\n",
       "      <td>-0.132262</td>\n",
       "      <td>0.021743</td>\n",
       "      <td>-0.107360</td>\n",
       "      <td>0.004203</td>\n",
       "      <td>-0.004731</td>\n",
       "      <td>0.083119</td>\n",
       "      <td>-0.092561</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045272</td>\n",
       "      <td>-0.277991</td>\n",
       "      <td>0.132882</td>\n",
       "      <td>-0.139432</td>\n",
       "      <td>0.164234</td>\n",
       "      <td>0.249621</td>\n",
       "      <td>-0.138952</td>\n",
       "      <td>0.304824</td>\n",
       "      <td>-0.253715</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.063686</td>\n",
       "      <td>0.055259</td>\n",
       "      <td>0.016241</td>\n",
       "      <td>-0.143958</td>\n",
       "      <td>0.101431</td>\n",
       "      <td>-0.023681</td>\n",
       "      <td>0.018424</td>\n",
       "      <td>0.020094</td>\n",
       "      <td>0.107365</td>\n",
       "      <td>-0.086338</td>\n",
       "      <td>...</td>\n",
       "      <td>0.282411</td>\n",
       "      <td>-0.113771</td>\n",
       "      <td>-0.113759</td>\n",
       "      <td>0.131902</td>\n",
       "      <td>-0.015990</td>\n",
       "      <td>-0.191980</td>\n",
       "      <td>-0.334883</td>\n",
       "      <td>0.061670</td>\n",
       "      <td>-0.158407</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.092163</td>\n",
       "      <td>0.032101</td>\n",
       "      <td>-0.014028</td>\n",
       "      <td>-0.149624</td>\n",
       "      <td>0.064407</td>\n",
       "      <td>-0.068130</td>\n",
       "      <td>-0.059455</td>\n",
       "      <td>0.004340</td>\n",
       "      <td>0.062144</td>\n",
       "      <td>-0.086675</td>\n",
       "      <td>...</td>\n",
       "      <td>0.141946</td>\n",
       "      <td>0.149528</td>\n",
       "      <td>0.076696</td>\n",
       "      <td>-0.095984</td>\n",
       "      <td>-0.008231</td>\n",
       "      <td>0.002515</td>\n",
       "      <td>0.170851</td>\n",
       "      <td>-0.085533</td>\n",
       "      <td>0.520633</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71532</th>\n",
       "      <td>-0.053145</td>\n",
       "      <td>0.077665</td>\n",
       "      <td>0.003893</td>\n",
       "      <td>-0.087140</td>\n",
       "      <td>0.037707</td>\n",
       "      <td>-0.091551</td>\n",
       "      <td>-0.014298</td>\n",
       "      <td>0.072125</td>\n",
       "      <td>0.075301</td>\n",
       "      <td>-0.127008</td>\n",
       "      <td>...</td>\n",
       "      <td>0.089624</td>\n",
       "      <td>-0.075370</td>\n",
       "      <td>0.231565</td>\n",
       "      <td>-0.313350</td>\n",
       "      <td>0.017313</td>\n",
       "      <td>0.137330</td>\n",
       "      <td>0.179112</td>\n",
       "      <td>0.041280</td>\n",
       "      <td>0.116232</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71533</th>\n",
       "      <td>-0.070634</td>\n",
       "      <td>0.044136</td>\n",
       "      <td>-0.013735</td>\n",
       "      <td>-0.164399</td>\n",
       "      <td>0.093419</td>\n",
       "      <td>-0.002283</td>\n",
       "      <td>0.027624</td>\n",
       "      <td>0.027545</td>\n",
       "      <td>0.099368</td>\n",
       "      <td>-0.109544</td>\n",
       "      <td>...</td>\n",
       "      <td>0.170566</td>\n",
       "      <td>-0.089431</td>\n",
       "      <td>0.378826</td>\n",
       "      <td>-0.163944</td>\n",
       "      <td>0.113110</td>\n",
       "      <td>-0.186374</td>\n",
       "      <td>0.076627</td>\n",
       "      <td>-0.210559</td>\n",
       "      <td>0.068129</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71534</th>\n",
       "      <td>-0.033054</td>\n",
       "      <td>0.085788</td>\n",
       "      <td>0.020429</td>\n",
       "      <td>-0.095798</td>\n",
       "      <td>0.085155</td>\n",
       "      <td>-0.105397</td>\n",
       "      <td>-0.003823</td>\n",
       "      <td>0.040178</td>\n",
       "      <td>0.044039</td>\n",
       "      <td>-0.075367</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021379</td>\n",
       "      <td>0.485554</td>\n",
       "      <td>0.214222</td>\n",
       "      <td>-0.286714</td>\n",
       "      <td>-0.078391</td>\n",
       "      <td>-0.009163</td>\n",
       "      <td>-0.104299</td>\n",
       "      <td>0.074132</td>\n",
       "      <td>0.155549</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71535</th>\n",
       "      <td>-0.053357</td>\n",
       "      <td>0.083096</td>\n",
       "      <td>0.031322</td>\n",
       "      <td>-0.130134</td>\n",
       "      <td>0.069392</td>\n",
       "      <td>-0.083105</td>\n",
       "      <td>-0.016291</td>\n",
       "      <td>0.006745</td>\n",
       "      <td>0.073288</td>\n",
       "      <td>-0.069151</td>\n",
       "      <td>...</td>\n",
       "      <td>0.538331</td>\n",
       "      <td>-0.164962</td>\n",
       "      <td>0.114452</td>\n",
       "      <td>-0.107142</td>\n",
       "      <td>0.043774</td>\n",
       "      <td>-0.039344</td>\n",
       "      <td>0.187251</td>\n",
       "      <td>0.166209</td>\n",
       "      <td>-0.272925</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71536</th>\n",
       "      <td>-0.040086</td>\n",
       "      <td>0.085912</td>\n",
       "      <td>0.036120</td>\n",
       "      <td>-0.120023</td>\n",
       "      <td>0.065185</td>\n",
       "      <td>-0.064514</td>\n",
       "      <td>0.005929</td>\n",
       "      <td>0.061235</td>\n",
       "      <td>0.095268</td>\n",
       "      <td>-0.053676</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062529</td>\n",
       "      <td>-0.318432</td>\n",
       "      <td>0.185536</td>\n",
       "      <td>0.009692</td>\n",
       "      <td>-0.001618</td>\n",
       "      <td>0.037776</td>\n",
       "      <td>-0.024205</td>\n",
       "      <td>0.054323</td>\n",
       "      <td>-0.001478</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70943 rows × 1001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "0     -0.086678  0.007570 -0.001760 -0.119879  0.025078 -0.057182  0.029155   \n",
       "2     -0.028979  0.035377  0.017578 -0.083165  0.102731 -0.049929 -0.021335   \n",
       "3     -0.029658  0.035590  0.020067 -0.132262  0.021743 -0.107360  0.004203   \n",
       "4     -0.063686  0.055259  0.016241 -0.143958  0.101431 -0.023681  0.018424   \n",
       "5     -0.092163  0.032101 -0.014028 -0.149624  0.064407 -0.068130 -0.059455   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "71532 -0.053145  0.077665  0.003893 -0.087140  0.037707 -0.091551 -0.014298   \n",
       "71533 -0.070634  0.044136 -0.013735 -0.164399  0.093419 -0.002283  0.027624   \n",
       "71534 -0.033054  0.085788  0.020429 -0.095798  0.085155 -0.105397 -0.003823   \n",
       "71535 -0.053357  0.083096  0.031322 -0.130134  0.069392 -0.083105 -0.016291   \n",
       "71536 -0.040086  0.085912  0.036120 -0.120023  0.065185 -0.064514  0.005929   \n",
       "\n",
       "              7         8         9  ...       991       992       993  \\\n",
       "0      0.016894  0.082843 -0.084654  ...  0.187143 -0.049634 -0.135729   \n",
       "2      0.058517  0.053307 -0.085223  ...  0.356400  0.355215 -0.028688   \n",
       "3     -0.004731  0.083119 -0.092561  ... -0.045272 -0.277991  0.132882   \n",
       "4      0.020094  0.107365 -0.086338  ...  0.282411 -0.113771 -0.113759   \n",
       "5      0.004340  0.062144 -0.086675  ...  0.141946  0.149528  0.076696   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "71532  0.072125  0.075301 -0.127008  ...  0.089624 -0.075370  0.231565   \n",
       "71533  0.027545  0.099368 -0.109544  ...  0.170566 -0.089431  0.378826   \n",
       "71534  0.040178  0.044039 -0.075367  ...  0.021379  0.485554  0.214222   \n",
       "71535  0.006745  0.073288 -0.069151  ...  0.538331 -0.164962  0.114452   \n",
       "71536  0.061235  0.095268 -0.053676  ... -0.062529 -0.318432  0.185536   \n",
       "\n",
       "            994       995       996       997       998       999  label  \n",
       "0     -0.168967 -0.101840 -0.059187 -0.523092 -0.014308  0.222151    1.0  \n",
       "2     -0.065168 -0.171425  0.204379  0.191221  0.038517 -0.241319    1.0  \n",
       "3     -0.139432  0.164234  0.249621 -0.138952  0.304824 -0.253715    0.0  \n",
       "4      0.131902 -0.015990 -0.191980 -0.334883  0.061670 -0.158407    1.0  \n",
       "5     -0.095984 -0.008231  0.002515  0.170851 -0.085533  0.520633    1.0  \n",
       "...         ...       ...       ...       ...       ...       ...    ...  \n",
       "71532 -0.313350  0.017313  0.137330  0.179112  0.041280  0.116232    0.0  \n",
       "71533 -0.163944  0.113110 -0.186374  0.076627 -0.210559  0.068129    0.0  \n",
       "71534 -0.286714 -0.078391 -0.009163 -0.104299  0.074132  0.155549    1.0  \n",
       "71535 -0.107142  0.043774 -0.039344  0.187251  0.166209 -0.272925    0.0  \n",
       "71536  0.009692 -0.001618  0.037776 -0.024205  0.054323 -0.001478    0.0  \n",
       "\n",
       "[70943 rows x 1001 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_row=pd.read_csv(\"/Users/withmocha/Desktop/DATA/BOAZ/미니 프로젝트 1/data/roberta-base/fake news vectored data.csv\",index_col=0)\n",
    "\n",
    "data_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_data=pd.DataFrame(data_row['label'])\n",
    "train_data=data_row.drop(labels='label',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>990</th>\n",
       "      <th>991</th>\n",
       "      <th>992</th>\n",
       "      <th>993</th>\n",
       "      <th>994</th>\n",
       "      <th>995</th>\n",
       "      <th>996</th>\n",
       "      <th>997</th>\n",
       "      <th>998</th>\n",
       "      <th>999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.086678</td>\n",
       "      <td>0.007570</td>\n",
       "      <td>-0.001760</td>\n",
       "      <td>-0.119879</td>\n",
       "      <td>0.025078</td>\n",
       "      <td>-0.057182</td>\n",
       "      <td>0.029155</td>\n",
       "      <td>0.016894</td>\n",
       "      <td>0.082843</td>\n",
       "      <td>-0.084654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.288966</td>\n",
       "      <td>0.187143</td>\n",
       "      <td>-0.049634</td>\n",
       "      <td>-0.135729</td>\n",
       "      <td>-0.168967</td>\n",
       "      <td>-0.101840</td>\n",
       "      <td>-0.059187</td>\n",
       "      <td>-0.523092</td>\n",
       "      <td>-0.014308</td>\n",
       "      <td>0.222151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.028979</td>\n",
       "      <td>0.035377</td>\n",
       "      <td>0.017578</td>\n",
       "      <td>-0.083165</td>\n",
       "      <td>0.102731</td>\n",
       "      <td>-0.049929</td>\n",
       "      <td>-0.021335</td>\n",
       "      <td>0.058517</td>\n",
       "      <td>0.053307</td>\n",
       "      <td>-0.085223</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.117906</td>\n",
       "      <td>0.356400</td>\n",
       "      <td>0.355215</td>\n",
       "      <td>-0.028688</td>\n",
       "      <td>-0.065168</td>\n",
       "      <td>-0.171425</td>\n",
       "      <td>0.204379</td>\n",
       "      <td>0.191221</td>\n",
       "      <td>0.038517</td>\n",
       "      <td>-0.241319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.029658</td>\n",
       "      <td>0.035590</td>\n",
       "      <td>0.020067</td>\n",
       "      <td>-0.132262</td>\n",
       "      <td>0.021743</td>\n",
       "      <td>-0.107360</td>\n",
       "      <td>0.004203</td>\n",
       "      <td>-0.004731</td>\n",
       "      <td>0.083119</td>\n",
       "      <td>-0.092561</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.205706</td>\n",
       "      <td>-0.045272</td>\n",
       "      <td>-0.277991</td>\n",
       "      <td>0.132882</td>\n",
       "      <td>-0.139432</td>\n",
       "      <td>0.164234</td>\n",
       "      <td>0.249621</td>\n",
       "      <td>-0.138952</td>\n",
       "      <td>0.304824</td>\n",
       "      <td>-0.253715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.063686</td>\n",
       "      <td>0.055259</td>\n",
       "      <td>0.016241</td>\n",
       "      <td>-0.143958</td>\n",
       "      <td>0.101431</td>\n",
       "      <td>-0.023681</td>\n",
       "      <td>0.018424</td>\n",
       "      <td>0.020094</td>\n",
       "      <td>0.107365</td>\n",
       "      <td>-0.086338</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.031097</td>\n",
       "      <td>0.282411</td>\n",
       "      <td>-0.113771</td>\n",
       "      <td>-0.113759</td>\n",
       "      <td>0.131902</td>\n",
       "      <td>-0.015990</td>\n",
       "      <td>-0.191980</td>\n",
       "      <td>-0.334883</td>\n",
       "      <td>0.061670</td>\n",
       "      <td>-0.158407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.092163</td>\n",
       "      <td>0.032101</td>\n",
       "      <td>-0.014028</td>\n",
       "      <td>-0.149624</td>\n",
       "      <td>0.064407</td>\n",
       "      <td>-0.068130</td>\n",
       "      <td>-0.059455</td>\n",
       "      <td>0.004340</td>\n",
       "      <td>0.062144</td>\n",
       "      <td>-0.086675</td>\n",
       "      <td>...</td>\n",
       "      <td>0.411422</td>\n",
       "      <td>0.141946</td>\n",
       "      <td>0.149528</td>\n",
       "      <td>0.076696</td>\n",
       "      <td>-0.095984</td>\n",
       "      <td>-0.008231</td>\n",
       "      <td>0.002515</td>\n",
       "      <td>0.170851</td>\n",
       "      <td>-0.085533</td>\n",
       "      <td>0.520633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71532</th>\n",
       "      <td>-0.053145</td>\n",
       "      <td>0.077665</td>\n",
       "      <td>0.003893</td>\n",
       "      <td>-0.087140</td>\n",
       "      <td>0.037707</td>\n",
       "      <td>-0.091551</td>\n",
       "      <td>-0.014298</td>\n",
       "      <td>0.072125</td>\n",
       "      <td>0.075301</td>\n",
       "      <td>-0.127008</td>\n",
       "      <td>...</td>\n",
       "      <td>0.370443</td>\n",
       "      <td>0.089624</td>\n",
       "      <td>-0.075370</td>\n",
       "      <td>0.231565</td>\n",
       "      <td>-0.313350</td>\n",
       "      <td>0.017313</td>\n",
       "      <td>0.137330</td>\n",
       "      <td>0.179112</td>\n",
       "      <td>0.041280</td>\n",
       "      <td>0.116232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71533</th>\n",
       "      <td>-0.070634</td>\n",
       "      <td>0.044136</td>\n",
       "      <td>-0.013735</td>\n",
       "      <td>-0.164399</td>\n",
       "      <td>0.093419</td>\n",
       "      <td>-0.002283</td>\n",
       "      <td>0.027624</td>\n",
       "      <td>0.027545</td>\n",
       "      <td>0.099368</td>\n",
       "      <td>-0.109544</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.124774</td>\n",
       "      <td>0.170566</td>\n",
       "      <td>-0.089431</td>\n",
       "      <td>0.378826</td>\n",
       "      <td>-0.163944</td>\n",
       "      <td>0.113110</td>\n",
       "      <td>-0.186374</td>\n",
       "      <td>0.076627</td>\n",
       "      <td>-0.210559</td>\n",
       "      <td>0.068129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71534</th>\n",
       "      <td>-0.033054</td>\n",
       "      <td>0.085788</td>\n",
       "      <td>0.020429</td>\n",
       "      <td>-0.095798</td>\n",
       "      <td>0.085155</td>\n",
       "      <td>-0.105397</td>\n",
       "      <td>-0.003823</td>\n",
       "      <td>0.040178</td>\n",
       "      <td>0.044039</td>\n",
       "      <td>-0.075367</td>\n",
       "      <td>...</td>\n",
       "      <td>0.359067</td>\n",
       "      <td>0.021379</td>\n",
       "      <td>0.485554</td>\n",
       "      <td>0.214222</td>\n",
       "      <td>-0.286714</td>\n",
       "      <td>-0.078391</td>\n",
       "      <td>-0.009163</td>\n",
       "      <td>-0.104299</td>\n",
       "      <td>0.074132</td>\n",
       "      <td>0.155549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71535</th>\n",
       "      <td>-0.053357</td>\n",
       "      <td>0.083096</td>\n",
       "      <td>0.031322</td>\n",
       "      <td>-0.130134</td>\n",
       "      <td>0.069392</td>\n",
       "      <td>-0.083105</td>\n",
       "      <td>-0.016291</td>\n",
       "      <td>0.006745</td>\n",
       "      <td>0.073288</td>\n",
       "      <td>-0.069151</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200794</td>\n",
       "      <td>0.538331</td>\n",
       "      <td>-0.164962</td>\n",
       "      <td>0.114452</td>\n",
       "      <td>-0.107142</td>\n",
       "      <td>0.043774</td>\n",
       "      <td>-0.039344</td>\n",
       "      <td>0.187251</td>\n",
       "      <td>0.166209</td>\n",
       "      <td>-0.272925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71536</th>\n",
       "      <td>-0.040086</td>\n",
       "      <td>0.085912</td>\n",
       "      <td>0.036120</td>\n",
       "      <td>-0.120023</td>\n",
       "      <td>0.065185</td>\n",
       "      <td>-0.064514</td>\n",
       "      <td>0.005929</td>\n",
       "      <td>0.061235</td>\n",
       "      <td>0.095268</td>\n",
       "      <td>-0.053676</td>\n",
       "      <td>...</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>-0.062529</td>\n",
       "      <td>-0.318432</td>\n",
       "      <td>0.185536</td>\n",
       "      <td>0.009692</td>\n",
       "      <td>-0.001618</td>\n",
       "      <td>0.037776</td>\n",
       "      <td>-0.024205</td>\n",
       "      <td>0.054323</td>\n",
       "      <td>-0.001478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70943 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "0     -0.086678  0.007570 -0.001760 -0.119879  0.025078 -0.057182  0.029155   \n",
       "2     -0.028979  0.035377  0.017578 -0.083165  0.102731 -0.049929 -0.021335   \n",
       "3     -0.029658  0.035590  0.020067 -0.132262  0.021743 -0.107360  0.004203   \n",
       "4     -0.063686  0.055259  0.016241 -0.143958  0.101431 -0.023681  0.018424   \n",
       "5     -0.092163  0.032101 -0.014028 -0.149624  0.064407 -0.068130 -0.059455   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "71532 -0.053145  0.077665  0.003893 -0.087140  0.037707 -0.091551 -0.014298   \n",
       "71533 -0.070634  0.044136 -0.013735 -0.164399  0.093419 -0.002283  0.027624   \n",
       "71534 -0.033054  0.085788  0.020429 -0.095798  0.085155 -0.105397 -0.003823   \n",
       "71535 -0.053357  0.083096  0.031322 -0.130134  0.069392 -0.083105 -0.016291   \n",
       "71536 -0.040086  0.085912  0.036120 -0.120023  0.065185 -0.064514  0.005929   \n",
       "\n",
       "              7         8         9  ...       990       991       992  \\\n",
       "0      0.016894  0.082843 -0.084654  ...  0.288966  0.187143 -0.049634   \n",
       "2      0.058517  0.053307 -0.085223  ... -0.117906  0.356400  0.355215   \n",
       "3     -0.004731  0.083119 -0.092561  ... -0.205706 -0.045272 -0.277991   \n",
       "4      0.020094  0.107365 -0.086338  ... -0.031097  0.282411 -0.113771   \n",
       "5      0.004340  0.062144 -0.086675  ...  0.411422  0.141946  0.149528   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "71532  0.072125  0.075301 -0.127008  ...  0.370443  0.089624 -0.075370   \n",
       "71533  0.027545  0.099368 -0.109544  ... -0.124774  0.170566 -0.089431   \n",
       "71534  0.040178  0.044039 -0.075367  ...  0.359067  0.021379  0.485554   \n",
       "71535  0.006745  0.073288 -0.069151  ...  0.200794  0.538331 -0.164962   \n",
       "71536  0.061235  0.095268 -0.053676  ...  0.205882 -0.062529 -0.318432   \n",
       "\n",
       "            993       994       995       996       997       998       999  \n",
       "0     -0.135729 -0.168967 -0.101840 -0.059187 -0.523092 -0.014308  0.222151  \n",
       "2     -0.028688 -0.065168 -0.171425  0.204379  0.191221  0.038517 -0.241319  \n",
       "3      0.132882 -0.139432  0.164234  0.249621 -0.138952  0.304824 -0.253715  \n",
       "4     -0.113759  0.131902 -0.015990 -0.191980 -0.334883  0.061670 -0.158407  \n",
       "5      0.076696 -0.095984 -0.008231  0.002515  0.170851 -0.085533  0.520633  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "71532  0.231565 -0.313350  0.017313  0.137330  0.179112  0.041280  0.116232  \n",
       "71533  0.378826 -0.163944  0.113110 -0.186374  0.076627 -0.210559  0.068129  \n",
       "71534  0.214222 -0.286714 -0.078391 -0.009163 -0.104299  0.074132  0.155549  \n",
       "71535  0.114452 -0.107142  0.043774 -0.039344  0.187251  0.166209 -0.272925  \n",
       "71536  0.185536  0.009692 -0.001618  0.037776 -0.024205  0.054323 -0.001478  \n",
       "\n",
       "[70943 rows x 1000 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71532</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71533</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71534</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71535</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71536</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70943 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label\n",
       "0        1.0\n",
       "2        1.0\n",
       "3        0.0\n",
       "4        1.0\n",
       "5        1.0\n",
       "...      ...\n",
       "71532    0.0\n",
       "71533    0.0\n",
       "71534    1.0\n",
       "71535    0.0\n",
       "71536    0.0\n",
       "\n",
       "[70943 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=train_data[30000:]\n",
    "y_train=target_data[30000:]\n",
    "x_test=train_data[:30000]\n",
    "y_test=target_data[:30000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "\n",
    "#scaler = StandardScaler()\n",
    "#x_train = scaler.fit_transform(x_train)\n",
    "#x_test = scaler.transform(x_test) # test set에는 transform만 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x_train = tf.cast(x_train, tf.float32)\n",
    "x_test = tf.cast(x_test, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.astype(bool)\n",
    "y_test = y_test.astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30212</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30213</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30214</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30215</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30216</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71532</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71533</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71534</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71535</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71536</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40943 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label\n",
       "30212   True\n",
       "30213  False\n",
       "30214  False\n",
       "30215   True\n",
       "30216   True\n",
       "...      ...\n",
       "71532  False\n",
       "71533  False\n",
       "71534   True\n",
       "71535  False\n",
       "71536  False\n",
       "\n",
       "[40943 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimension info : (40943, 1000, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train = tf.reshape(x_train,(x_train.shape[0],x_train.shape[1],1))\n",
    "x_test = tf.reshape(x_test,(x_test.shape[0],x_test.shape[1],1))\n",
    "print('dimension info :',x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/conda_cpu/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │        \u001b[38;5;34m16,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m66,048\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">83,073</span> (324.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m83,073\u001b[0m (324.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">83,073</span> (324.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m83,073\u001b[0m (324.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Dense, Bidirectional\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(LSTM(64, return_sequences=True, input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Bidirectional(LSTM(64, return_sequences=False)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "model_checkpoint = ModelCheckpoint('best_model.keras', save_best_only=True)\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m487s\u001b[0m 1s/step - accuracy: 0.5026 - loss: 0.6934 - val_accuracy: 0.5034 - val_loss: 0.6931\n",
      "Epoch 2/10\n",
      "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m442s\u001b[0m 987ms/step - accuracy: 0.5046 - loss: 0.6932 - val_accuracy: 0.5102 - val_loss: 0.6930\n",
      "Epoch 3/10\n",
      "\u001b[1m 87/448\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:09\u001b[0m 858ms/step - accuracy: 0.5072 - loss: 0.6929"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m training_record \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(x_train, y_train,\n\u001b[1;32m      2\u001b[0m                     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m      3\u001b[0m                     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m,\n\u001b[1;32m      4\u001b[0m                     callbacks\u001b[38;5;241m=\u001b[39m[early_stopping, model_checkpoint],\n\u001b[1;32m      5\u001b[0m                     validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m,\n\u001b[1;32m      6\u001b[0m                     shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/conda_cpu/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/conda_cpu/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:314\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    313\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 314\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[1;32m    315\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    316\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/conda_cpu/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/conda_cpu/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/conda_cpu/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[1;32m    879\u001b[0m     args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config\n\u001b[1;32m    880\u001b[0m )\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/conda_cpu/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[1;32m    141\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/conda_cpu/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mcall_preflattened(args)\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/conda_cpu/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_flat(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/conda_cpu/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[1;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    253\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    254\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[1;32m    255\u001b[0m     )\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/conda_cpu/lib/python3.12/site-packages/tensorflow/python/eager/context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[1;32m   1501\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1502\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   1503\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[1;32m   1504\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[1;32m   1505\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1506\u001b[0m   )\n\u001b[1;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1515\u001b[0m   )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/conda_cpu/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training_record = model.fit(x_train, y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=64,\n",
    "                    callbacks=[early_stopping, model_checkpoint],\n",
    "                    validation_split=0.3,\n",
    "                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 323us/step - accuracy: 1.0000 - loss: 8.9048e-08\n",
      "test acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(f'test acc: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('LSTM model.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
